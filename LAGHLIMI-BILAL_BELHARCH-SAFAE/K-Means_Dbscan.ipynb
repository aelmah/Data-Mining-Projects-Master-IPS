{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMyL94Yr1eh8PmJC37NfZo/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"kS1om7QLosCW"},"outputs":[],"source":["# 2Ô∏è‚É£ K-Means am√©lior√© par DBSCAN\n","#\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans, DBSCAN\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import silhouette_score, davies_bouldin_score, normalized_mutual_info_score\n","\n","#  Chargement et normalisation des donn√©es\n","df = pd.read_csv('/content/drive/MyDrive/project_dm/diabetes.csv')\n","scaler = StandardScaler()\n","data = scaler.fit_transform(df)\n","\n","#  D√©terminer le nombre optimal de clusters avec la m√©thode du coude (Elbow Method)\n","wcss = []\n","k_range = range(2, 15)\n","\n","for k in k_range:\n","    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n","    kmeans.fit(data)\n","    wcss.append(kmeans.inertia_)\n","\n","plt.plot(k_range, wcss, marker='o')\n","plt.xlabel('Nombre de clusters (k)')\n","plt.ylabel('WCSS')\n","plt.title('Elbow Method pour d√©terminer k optimal')\n","plt.show()\n","\n","#  Choix du nombre optimal de clusters (ajuster en fonction du graphique)\n","k_optimal = 5\n","\n","#  Appliquer K-Means\n","kmeans = KMeans(n_clusters=k_optimal, random_state=42, n_init=10)\n","kmeans_labels = kmeans.fit_predict(data)\n","df['Cluster_KMeans'] = kmeans_labels\n","\n","#  Appliquer DBSCAN pour am√©liorer le clustering\n","dbscan = DBSCAN(eps=1.5, min_samples=5)\n","dbscan_labels = dbscan.fit_predict(data)\n","\n","#  Correction du remplacement des outliers (-1) par la pr√©diction K-Means\n","dbscan_labels_fixed = np.copy(dbscan_labels)  # Copie des labels DBSCAN pour modification\n","\n","for i in range(len(dbscan_labels)):\n","    if dbscan_labels[i] == -1:  # Si c'est un outlier (-1)\n","        dbscan_labels_fixed[i] = kmeans_labels[i]  # Remplace par la pr√©diction K-Means\n","\n","df['Cluster_DBSCAN'] = dbscan_labels_fixed  # Mettre √† jour les clusters DBSCAN corrig√©s\n","\n","#  Visualisation des clusters (2D et 3D)\n","pca = PCA(n_components=2)\n","data_pca = pca.fit_transform(data)\n","\n","plt.scatter(data_pca[:, 0], data_pca[:, 1], c=df['Cluster_DBSCAN'], cmap='plasma', alpha=0.6)\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.title('Clusters apr√®s DBSCAN (2D)')\n","plt.colorbar(label='Cluster')\n","plt.show()\n","\n","pca_3d = PCA(n_components=3)\n","data_pca_3d = pca_3d.fit_transform(data)\n","\n","fig = plt.figure(figsize=(8, 6))\n","ax = fig.add_subplot(111, projection='3d')\n","ax.scatter(data_pca_3d[:, 0], data_pca_3d[:, 1], data_pca_3d[:, 2], c=df['Cluster_DBSCAN'], cmap='plasma', alpha=0.6)\n","ax.set_xlabel('PC1')\n","ax.set_ylabel('PC2')\n","ax.set_zlabel('PC3')\n","ax.set_title('Clusters apr√®s DBSCAN (3D)')\n","plt.show()\n","\n","# √âvaluation des performances\n","silhouette_avg_dbscan = silhouette_score(data, df['Cluster_DBSCAN'])\n","dbi_dbscan = davies_bouldin_score(data, df['Cluster_DBSCAN'])\n","nmi_score = normalized_mutual_info_score(df['Cluster_KMeans'], df['Cluster_DBSCAN'])\n","\n","print(f\"üìå Silhouette Score (DBSCAN): {silhouette_avg_dbscan:.4f}\")\n","print(f\"üìå Davies-Bouldin Index (DBSCAN): {dbi_dbscan:.4f}\")\n","print(f\"üìå NMI (K-Means vs DBSCAN): {nmi_score:.4f}\")\n","\n"]}]}