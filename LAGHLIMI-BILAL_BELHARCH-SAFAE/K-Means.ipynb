{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMsRB3aeMnJMGjX4dJ/RtMU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"gKToDPV5n3Hh"},"outputs":[],"source":["# 1ï¸âƒ£ K-Means seul\n","\n","\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from sklearn.cluster import KMeans\n","from sklearn.decomposition import PCA\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import silhouette_score, davies_bouldin_score, normalized_mutual_info_score\n","from scipy.stats import entropy\n","\n","# Chargement et normalisation des donnÃ©es\n","df = pd.read_csv('/content/drive/MyDrive/project_dm/diabetes.csv')\n","scaler = StandardScaler()\n","data = scaler.fit_transform(df)\n","\n","# MÃ©thode du Coude (Elbow Method) pour choisir k optimal\n","wcss = []\n","k_range = range(2, 15)\n","\n","for k in k_range:\n","    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n","    kmeans.fit(data)\n","    wcss.append(kmeans.inertia_)\n","\n","#  Affichage du graphique Elbow Method\n","plt.figure(figsize=(8, 5))\n","plt.plot(k_range, wcss, marker='o', linestyle='-')\n","plt.xlabel('Nombre de clusters (k)')\n","plt.ylabel('WCSS (Within-Cluster Sum of Squares)')\n","plt.title('MÃ©thode du coude pour dÃ©terminer k optimal')\n","plt.show()\n","\n","#  Validation avec le Silhouette Score\n","\n","best_k = 2\n","best_score = -1\n","silhouette_scores = []\n","\n","for k in range(2, 15):\n","    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n","    labels = kmeans.fit_predict(data)\n","    score = silhouette_score(data, labels)\n","    silhouette_scores.append(score)\n","\n","    if score > best_score:\n","        best_score = score\n","        best_k = k\n","\n","print(f\"ğŸ“Œ Le nombre optimal de clusters selon le Silhouette Score est: {best_k}\")\n","\n","#  Affichage du Silhouette Score en fonction de k\n","plt.figure(figsize=(8, 5))\n","plt.plot(range(2, 15), silhouette_scores, marker='o', linestyle='-')\n","plt.xlabel('Nombre de clusters (k)')\n","plt.ylabel('Silhouette Score')\n","plt.title('Silhouette Score pour diffÃ©rents k')\n","plt.show()\n","\n","# ğŸ“Œ 4ï¸âƒ£ Appliquer K-Means avec le k optimal\n","kmeans = KMeans(n_clusters=best_k, random_state=42, n_init=10)\n","kmeans_labels = kmeans.fit_predict(data)\n","df['Cluster_KMeans'] = kmeans_labels\n","\n","# # Calcul des mÃ©triques d'Ã©valuation :\n","\n","#  Silhouette Score\n","silhouette_avg = silhouette_score(data, kmeans_labels)\n","print(f\"ğŸ“Œ Silhouette Score: {silhouette_avg:.4f}\")\n","\n","#  Davies-Bouldin Index (DBI)\n","dbi = davies_bouldin_score(data, kmeans_labels)\n","print(f\"ğŸ“Œ Davies-Bouldin Index: {dbi:.4f}\")\n","\n","#  Normalized Mutual Information (NMI) (comparaison K-Means vs lui-mÃªme pour validation)\n","nmi_score = normalized_mutual_info_score(kmeans_labels, kmeans_labels)\n","print(f\"ğŸ“Œ Normalized Mutual Information (NMI): {nmi_score:.4f}\")\n","\n","#  Calcul de l'entropie des clusters\n","def calculate_entropy(labels):\n","    unique_labels, counts = np.unique(labels, return_counts=True)\n","    probabilities = counts / counts.sum()\n","    return entropy(probabilities, base=2)\n","\n","entropy_score = calculate_entropy(kmeans_labels)\n","print(f\"ğŸ“Œ Entropie des clusters: {entropy_score:.4f}\")\n","\n","# Visualisation des clusters en 2D (PCA)\n","pca = PCA(n_components=2)\n","data_pca = pca.fit_transform(data)\n","\n","plt.figure(figsize=(8, 6))\n","plt.scatter(data_pca[:, 0], data_pca[:, 1], c=kmeans_labels, cmap='viridis', alpha=0.6)\n","plt.xlabel('PC1')\n","plt.ylabel('PC2')\n","plt.title(f'Clusters K-Means avec k={best_k} (2D)')\n","plt.colorbar(label='Cluster')\n","plt.show()\n","\n","#  Visualisation des clusters en 3D (PCA)\n","pca_3d = PCA(n_components=3)\n","data_pca_3d = pca_3d.fit_transform(data)\n","\n","fig = plt.figure(figsize=(8, 6))\n","ax = fig.add_subplot(111, projection='3d')\n","ax.scatter(data_pca_3d[:, 0], data_pca_3d[:, 1], data_pca_3d[:, 2], c=kmeans_labels, cmap='viridis', alpha=0.6)\n","ax.set_xlabel('PC1')\n","ax.set_ylabel('PC2')\n","ax.set_zlabel('PC3')\n","ax.set_title(f'Clusters K-Means avec k={best_k} (3D)')\n","plt.show()\n","\n"]}]}